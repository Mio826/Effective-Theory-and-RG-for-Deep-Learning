{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920a580b-684a-4310-9f67-f4a0d682d44f",
   "metadata": {},
   "source": [
    "# $\\gamma = 1/2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee87281-581e-43f7-be42-5c6502ed6242",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ToyAttentionConfig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 31\u001b[0m\n\u001b[0;32m     19\u001b[0m gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     21\u001b[0m cfg \u001b[38;5;241m=\u001b[39m ExperimentConfig(\n\u001b[0;32m     22\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     }\n\u001b[0;32m     30\u001b[0m )\n\u001b[1;32m---> 31\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     33\u001b[0m B \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     34\u001b[0m s \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(B, L\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, d_model)\n",
      "File \u001b[1;32m~\\Github_rep\\Effective-Theory-and-RG-for-Deep-Learning\\Deep Learning Pack\\dlphys\\config\\registry.py:94\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(cfg)\u001b[0m\n\u001b[0;32m     92\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cfg\u001b[38;5;241m.\u001b[39mextra\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}) \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m     93\u001b[0m ctor \u001b[38;5;241m=\u001b[39m MODEL_REGISTRY\u001b[38;5;241m.\u001b[39mget(name)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctor(cfg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Github_rep\\Effective-Theory-and-RG-for-Deep-Learning\\Deep Learning Pack\\dlphys\\models\\registry.py:75\u001b[0m, in \u001b[0;36mbuild_toy_attention\u001b[1;34m(cfg, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_k\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoy_attention requires model_kwargs: \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124md_model: int, d_k: int, ...}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m mc \u001b[38;5;241m=\u001b[39m \u001b[43mToyAttentionConfig\u001b[49m(\n\u001b[0;32m     76\u001b[0m     d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     77\u001b[0m     d_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_k\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[0;32m     78\u001b[0m     L\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m8\u001b[39m)),\n\u001b[0;32m     79\u001b[0m     num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)),\n\u001b[0;32m     80\u001b[0m     gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)),\n\u001b[0;32m     81\u001b[0m     phi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midentity\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m     82\u001b[0m     bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbias\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)),\n\u001b[0;32m     83\u001b[0m     v_gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv_gain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)),   \u001b[38;5;66;03m# NEW\u001b[39;00m\n\u001b[0;32m     84\u001b[0m )\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ToyAttentionDynamics(mc)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ToyAttentionConfig' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "ROOT = Path.cwd().parent  # notebook/ 的 parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import dlphys.models  # trigger registration\n",
    "from dlphys.config.base import ExperimentConfig\n",
    "from dlphys.config.registry import build_model\n",
    "from dlphys.analysis.jvp import jvp_F\n",
    "from dlphys.utils.seed import set_seed\n",
    "\n",
    "set_seed(0, deterministic=True)\n",
    "\n",
    "L = 100\n",
    "d_model = 16\n",
    "d_k = 32\n",
    "gamma = 0.5\n",
    "\n",
    "cfg = ExperimentConfig(\n",
    "    project_name=\"toy\",\n",
    "    device=\"cpu\",\n",
    "    seed=0,\n",
    "    deterministic=True,\n",
    "    extra={\n",
    "        \"model_name\": \"toy_attention\",\n",
    "        \"model_kwargs\": dict(d_model=d_model, d_k=d_k, L=L, num_heads=1, gamma=gamma, phi=\"identity\"),\n",
    "    }\n",
    ")\n",
    "m = build_model(cfg).eval()\n",
    "\n",
    "B = 1\n",
    "s = torch.randn(B, L+1, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f55fa-fc82-4d8d-900c-03f82ecc0e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = m.Wq[0].weight\n",
    "print(\"Wq mean/std:\", w.mean().item(), w.std(unbiased=False).item())\n",
    "print(\"target std:\", 1.0 / (m.cfg.d_model ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874b117a-9773-461c-b546-162ab736a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlphys.analysis.lyapunov import lyapunov_max_benettin\n",
    "\n",
    "# 用同一个初态（或拷贝一份）\n",
    "s0 = s.clone()\n",
    "\n",
    "F = lambda _s: m(_s)\n",
    "\n",
    "out = lyapunov_max_benettin(\n",
    "    F, s0,\n",
    "    burn_in=int(1e4 * 0.9),\n",
    "    T=1e4,\n",
    "    return_traj=True\n",
    ")\n",
    "\n",
    "print(\"lambda_hat (per batch):\", out[\"lambda_hat\"])\n",
    "print(\"lambda_mean:\", out[\"lambda_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abaf8dbf-3ef1-4552-8172-4ba6b8f1b30c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msensitivity_profile\u001b[39m(m, s, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    Returns: sens[ L+1 ] where sens[tau] = E || d x_next / d s_tau || (via JVP)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     B, T, d \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def sensitivity_profile(m, s, n_trials=5):\n",
    "    \"\"\"\n",
    "    Returns: sens[ L+1 ] where sens[tau] = E || d x_next / d s_tau || (via JVP)\n",
    "    \"\"\"\n",
    "    B, T, d = s.shape\n",
    "    assert B == 1\n",
    "    F = lambda _s: m(_s)  # returns full s_next\n",
    "\n",
    "    sens = torch.zeros(T)\n",
    "    for tau in range(T):\n",
    "        vals = []\n",
    "        for _ in range(n_trials):\n",
    "            v = torch.zeros_like(s)\n",
    "            v[:, tau, :] = torch.randn_like(v[:, tau, :])  # perturb only this slot\n",
    "            jvp = jvp_F(F, s, v)  # shape [1,T,d]\n",
    "            dxnext = jvp[:, 0, :]  # output token perturbation\n",
    "            vals.append(dxnext.norm(dim=-1).item())\n",
    "        sens[tau] = sum(vals) / len(vals)\n",
    "    return sens\n",
    "\n",
    "sens = sensitivity_profile(m, s, n_trials=3)\n",
    "print(\"sens shape:\", sens.shape)\n",
    "print(\"sens (first 10):\", sens[:10])\n",
    "print(\"ratio max/min:\", (sens.max()/ (sens.min()+1e-12)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7db093ce-7fbd-4298-bab6-114fc5dae900",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43msens\u001b[49m \u001b[38;5;241m/\u001b[39m (sens\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-12\u001b[39m)\n\u001b[0;32m      2\u001b[0m entropy \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m(p \u001b[38;5;241m*\u001b[39m (p \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-12\u001b[39m)\u001b[38;5;241m.\u001b[39mlog())\u001b[38;5;241m.\u001b[39msum())\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m      3\u001b[0m entropy_uniform \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mfloat\u001b[39m(L\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)))\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sens' is not defined"
     ]
    }
   ],
   "source": [
    "p = sens / (sens.sum() + 1e-12)\n",
    "entropy = (-(p * (p + 1e-12).log()).sum()).item()\n",
    "entropy_uniform = torch.log(torch.tensor(float(L+1))).item()\n",
    "print(\"entropy proxy:\", entropy, \"uniform entropy:\", entropy_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b96e2d-8b77-4e2d-9803-388dbb1abbee",
   "metadata": {},
   "source": [
    "# $\\gamma=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3079704b-d096-4c8c-b2d1-5bc58eb32f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "ROOT = Path.cwd().parent  # notebook/ 的 parent\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import dlphys.models  # trigger registration\n",
    "from dlphys.config.base import ExperimentConfig\n",
    "from dlphys.config.registry import build_model\n",
    "from dlphys.analysis.jvp import jvp_F\n",
    "from dlphys.utils.seed import set_seed\n",
    "\n",
    "set_seed(0, deterministic=True)\n",
    "\n",
    "L = 200\n",
    "d_model = 16\n",
    "d_k = 32\n",
    "gamma = 0.8\n",
    "\n",
    "cfg = ExperimentConfig(\n",
    "    project_name=\"toy\",\n",
    "    device=\"cpu\",\n",
    "    seed=0,\n",
    "    deterministic=True,\n",
    "    extra={\n",
    "        \"model_name\": \"toy_attention\",\n",
    "        \"model_kwargs\": dict(d_model=d_model, d_k=d_k, L=L, num_heads=1, gamma=gamma, phi=\"identity\"),\n",
    "    }\n",
    ")\n",
    "m = build_model(cfg).eval()\n",
    "\n",
    "B = 1\n",
    "s = torch.randn(B, L+1, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c28b190-2e04-4b45-9e7b-5e4650ed5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_hat (per batch): tensor([-0.0053])\n",
      "lambda_mean: tensor(-0.0053)\n"
     ]
    }
   ],
   "source": [
    "from dlphys.analysis.lyapunov import lyapunov_max_benettin\n",
    "\n",
    "# 用同一个初态（或拷贝一份）\n",
    "s0 = s.clone()\n",
    "\n",
    "F = lambda _s: m(_s)\n",
    "\n",
    "out = lyapunov_max_benettin(\n",
    "    F, s0,\n",
    "    burn_in=int(2e4 * 0.9),\n",
    "    T=2e4,\n",
    "    return_traj=True\n",
    ")\n",
    "\n",
    "print(\"lambda_hat (per batch):\", out[\"lambda_hat\"])\n",
    "print(\"lambda_mean:\", out[\"lambda_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d48ebdd-8c8c-4391-a6b4-3c3acac53391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sens shape: torch.Size([201])\n",
      "sens (first 10): tensor([0.0848, 0.0108, 0.0140, 0.0088, 0.0121, 0.0145, 0.0090, 0.0139, 0.0098,\n",
      "        0.0112])\n",
      "ratio max/min: 11.59415054321289\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def sensitivity_profile(m, s, n_trials=5):\n",
    "    \"\"\"\n",
    "    Returns: sens[ L+1 ] where sens[tau] = E || d x_next / d s_tau || (via JVP)\n",
    "    \"\"\"\n",
    "    B, T, d = s.shape\n",
    "    assert B == 1\n",
    "    F = lambda _s: m(_s)  # returns full s_next\n",
    "\n",
    "    sens = torch.zeros(T)\n",
    "    for tau in range(T):\n",
    "        vals = []\n",
    "        for _ in range(n_trials):\n",
    "            v = torch.zeros_like(s)\n",
    "            v[:, tau, :] = torch.randn_like(v[:, tau, :])  # perturb only this slot\n",
    "            jvp = jvp_F(F, s, v)  # shape [1,T,d]\n",
    "            dxnext = jvp[:, 0, :]  # output token perturbation\n",
    "            vals.append(dxnext.norm(dim=-1).item())\n",
    "        sens[tau] = sum(vals) / len(vals)\n",
    "    return sens\n",
    "\n",
    "sens = sensitivity_profile(m, s, n_trials=3)\n",
    "print(\"sens shape:\", sens.shape)\n",
    "print(\"sens (first 10):\", sens[:10])\n",
    "print(\"ratio max/min:\", (sens.max()/ (sens.min()+1e-12)).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3badc348-ab38-4a27-b6f9-a940cc8ce6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy proxy: 5.250389099121094 uniform entropy: 5.303304672241211\n"
     ]
    }
   ],
   "source": [
    "p = sens / (sens.sum() + 1e-12)\n",
    "entropy = (-(p * (p + 1e-12).log()).sum()).item()\n",
    "entropy_uniform = torch.log(torch.tensor(float(L+1))).item()\n",
    "print(\"entropy proxy:\", entropy, \"uniform entropy:\", entropy_uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242c24a-9415-4887-bcec-3126b718c81a",
   "metadata": {},
   "source": [
    "# Gain test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e016dc-062e-486b-9460-7352a5772caa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlphys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdlphys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseed\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_seed\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdlphys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExperimentConfig\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdlphys\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlphys'"
     ]
    }
   ],
   "source": [
    "from dlphys.utils.seed import set_seed\n",
    "from dlphys.config.base import ExperimentConfig\n",
    "from dlphys.config.registry import build_model\n",
    "from dlphys.analysis.lyapunov import lyapunov_max_benettin\n",
    "import torch\n",
    "\n",
    "def run_lambda_for_gain(g_v, *, seed=0, L=200, d_model=16, d_k=32, gamma=0.5, H=1,\n",
    "                        burn_in=1500, T=2000, B=2, device=\"cpu\"):\n",
    "\n",
    "    set_seed(seed, deterministic=True)\n",
    "\n",
    "    model_kwargs = dict(\n",
    "        d_model=d_model,\n",
    "        d_k=d_k,\n",
    "        L=L,\n",
    "        num_heads=H,\n",
    "        gamma=gamma,\n",
    "        phi=\"identity\",\n",
    "        bias=False,\n",
    "        g_qk=1.0,\n",
    "        g_v=float(g_v),\n",
    "    )\n",
    "\n",
    "    cfg = ExperimentConfig(\n",
    "        project_name=\"toy\",\n",
    "        device=device,\n",
    "        seed=seed,\n",
    "        deterministic=True,\n",
    "        extra={\n",
    "            \"model_name\": \"toy_attention\",\n",
    "            \"model_kwargs\": model_kwargs,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # HARD CHECK (this should NOT be None)\n",
    "    print(\"DEBUG model_kwargs keys:\", cfg.extra[\"model_kwargs\"].keys())\n",
    "    print(\"DEBUG g_v passed:\", cfg.extra[\"model_kwargs\"].get(\"g_v\", None))\n",
    "\n",
    "    m = build_model(cfg).eval()\n",
    "    s0 = torch.randn(B, L+1, d_model, device=device)\n",
    "    F = lambda s: m(s)\n",
    "\n",
    "    out = lyapunov_max_benettin(F, s0, burn_in=burn_in, T=T, return_traj=False)\n",
    "    return out[\"lambda_mean\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3af74a7f-29de-427c-9f5b-0d9ff868e6dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 2.0\n",
      "lambda: 0.000786280375905335\n"
     ]
    }
   ],
   "source": [
    "lam = run_lambda_for_gain(2.0, seed=0)\n",
    "print(\"lambda:\", lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "052d54ad-5b21-47ef-a518-d624cc262c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 0.5\n",
      "g_v= 0.5: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 0.8\n",
      "g_v= 0.8: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 1.0\n",
      "g_v= 1.0: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 1.1\n",
      "g_v= 1.1: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 1.2\n",
      "g_v= 1.2: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 1.4\n",
      "g_v= 1.4: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 1.7\n",
      "g_v= 1.7: lambda_mean=+0.000786\n",
      "DEBUG model_kwargs keys: dict_keys(['d_model', 'd_k', 'L', 'num_heads', 'gamma', 'phi', 'bias', 'g_qk', 'g_v'])\n",
      "DEBUG g_v passed: 2.0\n",
      "g_v= 2.0: lambda_mean=+0.000786\n"
     ]
    }
   ],
   "source": [
    "g_list = [0.5, 0.8, 1.0, 1.1, 1.2, 1.4, 1.7, 2.0]\n",
    "for g in g_list:\n",
    "    lam = run_lambda_for_gain(g, seed=0)\n",
    "    print(f\"g_v={g:>4}: lambda_mean={lam:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "233e1a13-4b7c-4346-a9c0-1f8c556ba60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id(m) = 2390815094816\n",
      "m.cfg.g_v = 1.0 m.cfg.g_qk = 1.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'g_v'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# check actual weight scale\u001b[39;00m\n\u001b[0;32m      9\u001b[0m w \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mWv[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWv std =\u001b[39m\u001b[38;5;124m\"\u001b[39m, w\u001b[38;5;241m.\u001b[39mstd(unbiased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem(),\n\u001b[1;32m---> 11\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget ~\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mfloat\u001b[39m(\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_kwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mg_v\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(d_model))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# also check a deterministic hash-like scalar\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWv[0,0] =\u001b[39m\u001b[38;5;124m\"\u001b[39m, m\u001b[38;5;241m.\u001b[39mWv[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdetach()[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[1;31mKeyError\u001b[0m: 'g_v'"
     ]
    }
   ],
   "source": [
    "import math, torch\n",
    "\n",
    "print(\"id(m) =\", id(m))\n",
    "\n",
    "# check cfg inside model\n",
    "print(\"m.cfg.g_v =\", getattr(m.cfg, \"g_v\", None), \"m.cfg.g_qk =\", getattr(m.cfg, \"g_qk\", None))\n",
    "\n",
    "# check actual weight scale\n",
    "w = m.Wv[0].weight.detach().flatten()\n",
    "print(\"Wv std =\", w.std(unbiased=False).item(),\n",
    "      \"target ~\", float(cfg.extra[\"model_kwargs\"][\"g_v\"]) / math.sqrt(d_model))\n",
    "\n",
    "# also check a deterministic hash-like scalar\n",
    "print(\"Wv[0,0] =\", m.Wv[0].weight.detach()[0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4820a7e-13f1-4da3-bbd5-f77d3a2664b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
